## Введение

Проект представляет собой веб-приложение, которое принимает от пользователя документ в формате **.docx** и с помощью **LLM** (Large Language Model) извлекает из него ключевую информацию - основные тезисы, язык документа и простейшую текстовую аналитику. Результаты анализа возвращаются пользователю в виде файла **.docx** (есть возможность отправки на email) или в виде текста. 

Бэкенд проекта реализован на **FastAPI** и использует широкий набор библиотек для обработки текста и интеграции с **LLM**.
Фронтенд построен на **React** и обеспечивает взаимодействие с пользователем через удобный интерфейс, а также обращение к серверу с помощью **Axios**.

В проекте реализована аутентификация пользователей с помощью **JWT-токенов**, что позволяет ограничивать количество запросов, обрабатываемых каждым пользователем (механизм rate limiter). Все загруженные и сгенерированные файлы хранятся в **S3-хранилище**, а данные пользователей — в базе данных **PostgreSQL**.

Для управления базой данных используются **Alembic** (миграции и ревизии) и **SQLAlchemy** ORM, через которую также реализуется аналитика данных.
Проксирование и разделение доступа к фронтенду и бэкенду осуществляется через **Nginx**, а взаимодействие между микросервисами — через **RabbitMQ**, что обеспечивает отказ от монолитной архитектуры и улучшает масштабируемость системы.

Проект полностью контейнеризирован и может быть запущен локально в несколько кликов с помощью **Docker Compose**.
Код оформлен в соответствии с требованиями линтеров и форматеров, настроен **CI**, а также написаны тесты для бэкенда с использованием **pytest**.


## Цель проекта

Главная цель проекта — на практике освоить базовые принципы интеграции **LLM** и перехода от монолитной архитектуры к микросервисной с использованием **RabbitMQ**.

Дополнительные задачи включают:

- изучение принципов работы с **S3-хранилищами** для загрузки и хранения пользовательских файлов (.docx и .txt);

- углубление навыков frontend-разработки и понимания внутренней логики **React**;

- практическое освоение передачи файлов между фронтендом и бэкендом;

- интеграцию с библиотекой для отправки email-сообщений.

Проект призван объединить навыки работы с современными технологиями backend, frontend и DevOps, а также продемонстрировать умение создавать полнофункциональные приложения с использованием микросервисного подхода и инструментов автоматизации.

## Этапы разработки Бэкенда

1. Инициализация начальных инструментов

- Создание каркаса проекта с выгрузкой бэкенда сразу в docker-compose (опыт показал, что так будет проще отлаживать проект, чем в дальнейшем готовый локально код интегрировать в docker)
- Добавление тестирования по ходу построения и создания новой функциональности (опыт показал, что проще инициализировать pytest на ранних этапах разработки, хоть и замедлит процесс создания нового функционала, но таким образом автоматизируем большую часть рутинных проверок)
- Добавление линтера pylint и форматера black (опыт показал, что лучше изначально придерживаться каких-то стандартов разработки по качеству единообразия)
- Введенеие удобной структуры вызова команд через Makefile, который избавляет от запоминания множества сопряженных команд
- Введение модуля простейшего логирования
- Добавление CI

2. Написание микросервиса базы данных

- Инициализация СУБД PostgreSQL через docker-compose
- Написание модуля для взаимодействия Alembic и SQLAlchemy
- Написание классов SQLAlchemy для миграций и ревизий

3. Написание микросервиса основного бэкенда (авторизация и аутентификация)

- Инициализация модуля авторизации и аутентификации через JWT-токены 
- Реализация логики эндпоинтов (отправка email-подтверждения, добавление в БД новых пользователей, повторная отправка кода на email, генерация кодов)
- Использование pydantic и pydantic-settings для сериализации структуры и также использование env-файла для хранения "секретов"
- Лимитеры запросов

4. Написание микросервиса основного бэкенда (работа с файлами)

- Применение лимитера запросов на эндпоинты работы с файлами
- Разработка CRUD для энпдоинтов файлов
- Инициализация RabbitMQ и Celery для отправки в сервис LLM текста 
- Реализация логики эндпоинтов (получение файлов .docx, сохранение названия файлов в БД и самих файлов в S3, отправка на email)
- Иниализация S3 для хранения файлов
- Интеграция Celery

5. Написание микросервиса LLM

- Добавление нового сервиса в docker 
- Добавление для него функциональности проверка с тестированием
- Связывание через RabbitMQ файла микросервиса основного бэкенда
- Интегрирование LLM для преобразования текста

6. Написание микросервиса основного бэкенда (аналитика)

- Добавление бизнес-логики для работы с БД конкретного 
пользователя с аналитикой
- Реализация для него тестирования 
- Добавление лимитера запросов

